# Use callbacks/curriculum_update_callback=uniform to override callback. The default is uniform. 

- id: 1
  name: 'Qwen2.5-0.5B-GSM8k-uniform-1to1-0to0'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k trainer_args=vllm"
- id: 2
  name: 'Qwen2.5-0.5B-GSM8k-uniform-1to0-0.8to0'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k trainer_args=vllm callbacks.curriculum_update_callback.lower_bound_init=0.8 callbacks.curriculum_update_callback.upper_bound_final=0.0"
- id: 3
  name: 'Qwen2.5-0.5B-GSM8k-uniform-1to0-0to0'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k trainer_args=vllm callbacks.curriculum_update_callback.upper_bound_final=0.0"
- id: 4
  name: 'Qwen2.5-0.5B-GSM8k-uniform-0to0-0to0-no-cur'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k trainer_args=vllm callbacks.curriculum_update_callback.upper_bound_final=0.0 callbacks.curriculum_update_callback.upper_bound_init=0.0"

# MATH - Qwen 0.5B

- id: 5
  name: 'Qwen2.5-0.5B-MATH-uniform-1to1-0to0'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math trainer_args=vllm"

- id: 6
  name: 'Qwen2.5-0.5B-MATH-uniform-1to0-0.8to0'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math trainer_args=vllm callbacks.curriculum_update_callback.lower_bound_init=0.8 callbacks.curriculum_update_callback.upper_bound_final=0.0"

- id: 7
  name: 'Qwen2.5-0.5B-MATH-uniform-1to0-0to0'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math trainer_args=vllm callbacks.curriculum_update_callback.upper_bound_final=0.0"

- id: 8
  name: 'Qwen2.5-0.5B-MATH-uniform-0to0-0to0-no-cur'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math trainer_args=vllm callbacks.curriculum_update_callback.upper_bound_final=0.0 callbacks.curriculum_update_callback.upper_bound_init=0.0"

# MATH - Qwen 1.5B
- id: 9
  name: 'Qwen2.5-1.5B-MATH-uniform-1to1-0to0'
  model: 'Qwen/Qwen2-1.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math model=qwen_1.5b trainer_args=vllm"

- id: 10
  name: 'Qwen2.5-1.5B-MATH-uniform-1to0-0.8to0'
  model: 'Qwen/Qwen2-1.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math model=qwen_1.5b trainer_args=vllm callbacks.curriculum_update_callback.lower_bound_init=0.8 callbacks.curriculum_update_callback.upper_bound_final=0.0"

- id: 11
  name: 'Qwen2.5-1.5B-MATH-uniform-1to0-0to0'
  model: 'Qwen/Qwen2-1.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math model=qwen_1.5b trainer_args=vllm callbacks.curriculum_update_callback.upper_bound_final=0.0"

- id: 12
  name: 'Qwen2.5-1.5B-MATH-uniform-0to0-0to0-no-cur'
  model: 'Qwen/Qwen2-1.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math model=qwen_1.5b trainer_args=vllm callbacks.curriculum_update_callback.upper_bound_final=0.0 callbacks.curriculum_update_callback.upper_bound_init=0.0"

- id: 13
  name: ''
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k model=qwen_0.5b trainer_args=vllm"

- id: 14 
  name: 'Qwen2.5-0.5B-GSM8k-adaptive'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k trainer_args=vllm"

- id: 15
  name: 'Qwen2.5-1.5B-MATH-adaptive'
  model: 'Qwen/Qwen2-1.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_math model=qwen_1.5b trainer_args=vllm"

- id: 16
  name: 'Qwen2.5-0.5B-GSM8k-adaptive'
  model: 'Qwen/Qwen2-0.5B-Instruct'
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=qwen_gsm8k trainer_args=vllm max_steps=1800"

#######
- id: 20
  name: "gpt2-xl-gsm8k-adaptive-0.125-id-20"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=gpt2xl_1.5b task=gsm8k "
- id: 21
  name: "gpt2-xl-math-adaptive-0.125-id-21"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=gpt2xl_1.5b task=math trainer_args.max_completion_length=1000"
- id: 22
  name: "gpt2-xl-gsm8k-adaptive-0.25-id-22"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=gpt2xl_1.5b task=gsm8k "
- id: 23
  name: "gpt2-xl-math-adaptive-0.25-id-23"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=gpt2xl_1.5b task=math trainer_args.max_completion_length=1000"
- id: 24
  name: "gpt2-xl-gsm8k-adaptive-0.5-id-24"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=gpt2xl_1.5b task=gsm8k "
- id: 25
  name: "gpt2-xl-math-adaptive-0.5-id-25"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=gpt2xl_1.5b task=math trainer_args.max_completion_length=1000"
- id: 26
  name: "gpt2-xl-gsm8k-adaptive-0.625-id-26"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=gpt2xl_1.5b task=gsm8k "
- id: 27
  name: "gpt2-xl-math-adaptive-0.625-id-27"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=gpt2xl_1.5b task=math trainer_args.max_completion_length=1000"
- id: 28
  name: "gpt2-xl-gsm8k-adaptive-0.875-id-28"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=gpt2xl_1.5b task=gsm8k "
- id: 29
  name: "gpt2-xl-math-adaptive-0.875-id-29"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=gpt2xl_1.5b task=math trainer_args.max_completion_length=1000"
- id: 30
  name: "ph4mini-gsm8k-adaptive-0.125-id-30"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=phi4_4b task=gsm8k "
- id: 31
  name: "ph4mini-math-adaptive-0.125-id-31"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=phi4_4b task=math trainer_args.max_completion_length=1000"
- id: 32
  name: "ph4mini-gsm8k-adaptive-0.25-id-32"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=phi4_4b task=gsm8k "
- id: 33
  name: "ph4mini-math-adaptive-0.25-id-33"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=phi4_4b task=math trainer_args.max_completion_length=1000"
- id: 34
  name: "ph4mini-gsm8k-adaptive-0.5-id-34"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=phi4_4b task=gsm8k "
- id: 35
  name: "ph4mini-math-adaptive-0.5-id-35"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=phi4_4b task=math trainer_args.max_completion_length=1000"
- id: 36
  name: "ph4mini-gsm8k-adaptive-0.625-id-36"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=phi4_4b task=gsm8k "
- id: 37
  name: "ph4mini-math-adaptive-0.625-id-37"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=phi4_4b task=math trainer_args.max_completion_length=1000"
- id: 38
  name: "ph4mini-gsm8k-adaptive-0.875-id-38"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=phi4_4b task=gsm8k "
- id: 39
  name: "ph4mini-math-adaptive-0.875-id-39"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=phi4_4b task=math trainer_args.max_completion_length=1000"
- id: 40
  name: "Qwen2-0.5B-gsm8k-adaptive-0.125-id-40"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_0.5b task=gsm8k "
- id: 41
  name: "Qwen2-0.5B-math-adaptive-0.125-id-41"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_0.5b task=math trainer_args.max_completion_length=1000"
- id: 42
  name: "Qwen2-0.5B-gsm8k-adaptive-0.25-id-42"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_0.5b task=gsm8k "
- id: 43
  name: "Qwen2-0.5B-math-adaptive-0.25-id-43"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_0.5b task=math trainer_args.max_completion_length=1000"
- id: 44
  name: "Qwen2-0.5B-gsm8k-adaptive-0.5-id-44"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_0.5b task=gsm8k "
- id: 45
  name: "Qwen2-0.5B-math-adaptive-0.5-id-45"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_0.5b task=math trainer_args.max_completion_length=1000"
- id: 46
  name: "Qwen2-0.5B-gsm8k-adaptive-0.625-id-46"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_0.5b task=gsm8k "
- id: 47
  name: "Qwen2-0.5B-math-adaptive-0.625-id-47"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_0.5b task=math trainer_args.max_completion_length=1000"
- id: 48
  name: "Qwen2-0.5B-gsm8k-adaptive-0.875-id-48"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_0.5b task=gsm8k "
- id: 49
  name: "Qwen2-0.5B-math-adaptive-0.875-id-49"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_0.5b task=math trainer_args.max_completion_length=1000"
- id: 50
  name: "Qwen2-1.5B-gsm8k-adaptive-0.125-id-50"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_1.5b task=gsm8k "
- id: 51
  name: "Qwen2-1.5B-math-adaptive-0.125-id-51"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_1.5b task=math trainer_args.max_completion_length=1000"
- id: 52
  name: "Qwen2-1.5B-gsm8k-adaptive-0.25-id-52"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_1.5b task=gsm8k "
- id: 53
  name: "Qwen2-1.5B-math-adaptive-0.25-id-53"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_1.5b task=math trainer_args.max_completion_length=1000"
- id: 54
  name: "Qwen2-1.5B-gsm8k-adaptive-0.5-id-54"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_1.5b task=gsm8k "
- id: 55
  name: "Qwen2-1.5B-math-adaptive-0.5-id-55"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_1.5b task=math trainer_args.max_completion_length=1000"
- id: 56
  name: "Qwen2-1.5B-gsm8k-adaptive-0.625-id-56"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_1.5b task=gsm8k "
- id: 57
  name: "Qwen2-1.5B-math-adaptive-0.625-id-57"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_1.5b task=math trainer_args.max_completion_length=1000"
- id: 58
  name: "Qwen2-1.5B-gsm8k-adaptive-0.875-id-58"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_1.5b task=gsm8k "
- id: 59
  name: "Qwen2-1.5B-math-adaptive-0.875-id-59"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_1.5b task=math trainer_args.max_completion_length=1000"
- id: 60
  name: "Qwen2-7B-gsm8k-adaptive-0.125-id-60"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_7b task=gsm8k "
- id: 61
  name: "Qwen2-7B-math-adaptive-0.125-id-61"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_7b task=math trainer_args.max_completion_length=1000"
- id: 62
  name: "Qwen2-7B-gsm8k-adaptive-0.25-id-62"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_7b task=gsm8k "
- id: 63
  name: "Qwen2-7B-math-adaptive-0.25-id-63"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_7b task=math trainer_args.max_completion_length=1000"
- id: 64
  name: "Qwen2-7B-gsm8k-adaptive-0.5-id-64"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_7b task=gsm8k "
- id: 65
  name: "Qwen2-7B-math-adaptive-0.5-id-65"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_7b task=math trainer_args.max_completion_length=1000"
- id: 66
  name: "Qwen2-7B-gsm8k-adaptive-0.625-id-66"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_7b task=gsm8k "
- id: 67
  name: "Qwen2-7B-math-adaptive-0.625-id-67"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_7b task=math trainer_args.max_completion_length=1000"
- id: 68
  name: "Qwen2-7B-gsm8k-adaptive-0.875-id-68"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_7b task=gsm8k "
- id: 69
  name: "Qwen2-7B-math-adaptive-0.875-id-69"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_7b task=math trainer_args.max_completion_length=1000"
- id: 70
  name: "Qwen2-0.5B-Instruct-gsm8k-adaptive-0.125-id-70"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_instr_0.5b task=gsm8k "
- id: 71
  name: "Qwen2-0.5B-Instruct-math-adaptive-0.125-id-71"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_instr_0.5b task=math trainer_args.max_completion_length=1000"
- id: 72
  name: "Qwen2-0.5B-Instruct-gsm8k-adaptive-0.25-id-72"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_instr_0.5b task=gsm8k "
- id: 73
  name: "Qwen2-0.5B-Instruct-math-adaptive-0.25-id-73"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_instr_0.5b task=math trainer_args.max_completion_length=1000"
- id: 74
  name: "Qwen2-0.5B-Instruct-gsm8k-adaptive-0.5-id-74"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_instr_0.5b task=gsm8k "
- id: 75
  name: "Qwen2-0.5B-Instruct-math-adaptive-0.5-id-75"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_instr_0.5b task=math trainer_args.max_completion_length=1000"
- id: 76
  name: "Qwen2-0.5B-Instruct-gsm8k-adaptive-0.625-id-76"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_instr_0.5b task=gsm8k "
- id: 77
  name: "Qwen2-0.5B-Instruct-math-adaptive-0.625-id-77"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_instr_0.5b task=math trainer_args.max_completion_length=1000"
- id: 78
  name: "Qwen2-0.5B-Instruct-gsm8k-adaptive-0.875-id-78"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_instr_0.5b task=gsm8k "
- id: 79
  name: "Qwen2-0.5B-Instruct-math-adaptive-0.875-id-79"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_instr_0.5b task=math trainer_args.max_completion_length=1000"
- id: 80
  name: "Qwen2-1.5B-Instruct-gsm8k-adaptive-0.125-id-80"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_instr_1.5b task=gsm8k "
- id: 81
  name: "Qwen2-1.5B-Instruct-math-adaptive-0.125-id-81"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_instr_1.5b task=math trainer_args.max_completion_length=1000"
- id: 82
  name: "Qwen2-1.5B-Instruct-gsm8k-adaptive-0.25-id-82"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_instr_1.5b task=gsm8k "
- id: 83
  name: "Qwen2-1.5B-Instruct-math-adaptive-0.25-id-83"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_instr_1.5b task=math trainer_args.max_completion_length=1000"
- id: 84
  name: "Qwen2-1.5B-Instruct-gsm8k-adaptive-0.5-id-84"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_instr_1.5b task=gsm8k "
- id: 85
  name: "Qwen2-1.5B-Instruct-math-adaptive-0.5-id-85"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_instr_1.5b task=math trainer_args.max_completion_length=1000"
- id: 86
  name: "Qwen2-1.5B-Instruct-gsm8k-adaptive-0.625-id-86"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_instr_1.5b task=gsm8k "
- id: 87
  name: "Qwen2-1.5B-Instruct-math-adaptive-0.625-id-87"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_instr_1.5b task=math trainer_args.max_completion_length=1000"
- id: 88
  name: "Qwen2-1.5B-Instruct-gsm8k-adaptive-0.875-id-88"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_instr_1.5b task=gsm8k "
- id: 89
  name: "Qwen2-1.5B-Instruct-math-adaptive-0.875-id-89"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_instr_1.5b task=math trainer_args.max_completion_length=1000"
- id: 90
  name: "Qwen2-7B-Instruct-gsm8k-adaptive-0.125-id-90"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_instr_7b task=gsm8k "
- id: 91
  name: "Qwen2-7B-Instruct-math-adaptive-0.125-id-91"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.125 model=qwen_instr_7b task=math trainer_args.max_completion_length=1000"
- id: 92
  name: "Qwen2-7B-Instruct-gsm8k-adaptive-0.25-id-92"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_instr_7b task=gsm8k "
- id: 93
  name: "Qwen2-7B-Instruct-math-adaptive-0.25-id-93"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.25 model=qwen_instr_7b task=math trainer_args.max_completion_length=1000"
- id: 94
  name: "Qwen2-7B-Instruct-gsm8k-adaptive-0.5-id-94"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_instr_7b task=gsm8k "
- id: 95
  name: "Qwen2-7B-Instruct-math-adaptive-0.5-id-95"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.5 model=qwen_instr_7b task=math trainer_args.max_completion_length=1000"
- id: 96
  name: "Qwen2-7B-Instruct-gsm8k-adaptive-0.625-id-96"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_instr_7b task=gsm8k "
- id: 97
  name: "Qwen2-7B-Instruct-math-adaptive-0.625-id-97"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.625 model=qwen_instr_7b task=math trainer_args.max_completion_length=1000"
- id: 98
  name: "Qwen2-7B-Instruct-gsm8k-adaptive-0.875-id-98"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_instr_7b task=gsm8k "
- id: 99
  name: "Qwen2-7B-Instruct-math-adaptive-0.875-id-99"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=adaptive trainer_args=vllm dataset_wrapper.reward_threshold=0.875 model=qwen_instr_7b task=math trainer_args.max_completion_length=1000"


- id: 100
  name: "gpt2-xl-gsm8k-baseline-id-100"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=gpt2xl_1.5b task=gsm8k "
- id: 101
  name: "gpt2-xl-math-baseline-id-101"
  model: "openai-community/gpt2-xl"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=gpt2xl_1.5b task=math trainer_args.max_completion_length=1000"
- id: 102
  name: "ph4mini-gsm8k-baseline-id-102"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=phi4_4b task=gsm8k "
- id: 103
  name: "ph4mini-math-baseline-id-103"
  model: "microsoft/Phi-4-mini-instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=phi4_4b task=math trainer_args.max_completion_length=1000"
- id: 104
  name: "Qwen2-0.5B-gsm8k-baseline-id-104"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_0.5b task=gsm8k "
- id: 105
  name: "Qwen2-0.5B-math-baseline-id-105"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_0.5b task=math trainer_args.max_completion_length=1000"
- id: 106
  name: "Qwen2-1.5B-gsm8k-baseline-id-106"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_1.5b task=gsm8k "
- id: 107
  name: "Qwen2-1.5B-math-baseline-id-107"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_1.5b task=math trainer_args.max_completion_length=1000"
- id: 108
  name: "Qwen2-7B-gsm8k-baseline-id-108"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_7b task=gsm8k "
- id: 109
  name: "Qwen2-7B-math-baseline-id-109"
  model: "Qwen/Qwen2-7B"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_7b task=math trainer_args.max_completion_length=1000"
- id: 110
  name: "Qwen2-0.5B-Instruct-gsm8k-baseline-id-110"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_instr_0.5b task=gsm8k "
- id: 111
  name: "Qwen2-0.5B-Instruct-math-baseline-id-111"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_instr_0.5b task=math trainer_args.max_completion_length=1000"
- id: 112
  name: "Qwen2-1.5B-Instruct-gsm8k-baseline-id-112"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_instr_1.5b task=gsm8k "
- id: 113
  name: "Qwen2-1.5B-Instruct-math-baseline-id-113"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=default trainer_args=vllm model=qwen_instr_1.5b task=math trainer_args.max_completion_length=1000"
- id: 114
  name: "Qwen2-7B-Instruct-gsm8k-baseline-id-114"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=default trainer_args=vllm model=qwen_instr_7b task=gsm8k "
- id: 115
  name: "Qwen2-7B-Instruct-math-baseline-id-115"
  model: "Qwen/Qwen2-7B-Instruct"
  command: "accelerate launch --num_processes 7 --config_file ./config/deepspeed_zero3.yaml src/train.py experiment=default trainer_args=vllm model=qwen_instr_7b task=math trainer_args.max_completion_length=1000"


# PPO

- id: 200
  name: "Qwen2-0.5B-gsm8k-PPO-baseline-id-200"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_0.5b task=gsm8k dataset_wrapper=default"
- id: 201
  name: "Qwen2-0.5B-gsm8k-PPO-adaptive-0.5-id-201"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 202
  name: "Qwen2-0.5B-math-PPO-baseline-id-202"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_0.5b task=math dataset_wrapper=default"
- id: 203
  name: "Qwen2-0.5B-math-PPO-adaptive-0.5-id-203"
  model: "Qwen/Qwen2-0.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_0.5b task=math dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 204
  name: "Qwen2-1.5B-gsm8k-PPO-baseline-id-204"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L512 model=qwen_1.5b task=gsm8k dataset_wrapper=default"
- id: 205
  name: "Qwen2-1.5B-gsm8k-PPO-adaptive-0.5-id-205"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L512 model=qwen_1.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 206
  name: "Qwen2-1.5B-math-PPO-baseline-id-206"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L1024 model=qwen_1.5b task=math dataset_wrapper=default"
- id: 207
  name: "Qwen2-1.5B-math-PPO-adaptive-0.5-id-207"
  model: "Qwen/Qwen2-1.5B"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L1024 model=qwen_1.5b task=math dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 208
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-id-208"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default"
- id: 209
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-id-209"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 210
  name: "Qwen2-0.5B-Instruct-math-PPO-baseline-id-210"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_instr_0.5b task=math dataset_wrapper=default"
- id: 211
  name: "Qwen2-0.5B-Instruct-math-PPO-adaptive-0.5-id-211"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_instr_0.5b task=math dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 212
  name: "Qwen2-1.5B-Instruct-gsm8k-PPO-baseline-id-212"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L512 model=qwen_instr_1.5b task=gsm8k dataset_wrapper=default"
- id: 213
  name: "Qwen2-1.5B-Instruct-gsm8k-PPO-adaptive-0.5-id-213"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L512 model=qwen_instr_1.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"
- id: 214
  name: "Qwen2-1.5B-Instruct-math-PPO-baseline-id-214"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L1024 model=qwen_instr_1.5b task=math dataset_wrapper=default"
- id: 215
  name: "Qwen2-1.5B-Instruct-math-PPO-adaptive-0.5-id-215"
  model: "Qwen/Qwen2-1.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L1024 model=qwen_instr_1.5b task=math dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"




- id: 216
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-id-216"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default"
- id: 217
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-id-217"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5"

- id: 218
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-coef.1-id-218"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.1"
- id: 219
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.1-id-219"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.1"

- id: 220
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-coef.00001-id-220"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.00001"
- id: 221
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.00001-id-221"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.00001"

- id: 222
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.1-id-222"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.1"

- id: 223
  name: "RhoMath-1B-gsm8k-PPO-baseline-coef.1-id-223"
  model: "microsoft/rho-math-1b-v0.1"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_1.5b_L512 model=rhomath-1b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.1"


- id: 224
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-224"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2"

- id: 225
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-225"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001"

- id: 226
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-226"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.15"

- id: 227
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-227"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.learning_rate=1.0e-6"

- id: 228
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-228"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.gradient_accumulation_steps=12"

- id: 229
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-229"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3"

- id: 230
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-230"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.vf_coef=0.5"

######

- id: 231
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-231"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2"

- id: 232
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-232"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001"

- id: 233
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-233"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.15"

- id: 234
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-234"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.learning_rate=1.0e-6"

- id: 235
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-235"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.gradient_accumulation_steps=12"

- id: 236
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-236"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3"

- id: 237
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-baseline-0.5-coef.2-id-237"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.vf_coef=0.5"

######

- id: 238
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-238"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=4"

- id: 239
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-239"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.01 trainer.args.num_ppo_epochs=4"

- id: 240
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-240"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.05 trainer.args.num_ppo_epochs=4"

- id: 241
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-241"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=4 +trainer.args.missing_eos_penalty=0.3"

- id: 242
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-242"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=4"

- id: 243
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-243"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.01 trainer.args.num_ppo_epochs=4"

######

- id: 244
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-244"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.01 trainer.args.num_ppo_epochs=3"

- id: 245
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-245"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.05 trainer.args.num_ppo_epochs=3"

- id: 246
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-246"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.0 trainer.args.num_ppo_epochs=3"

- id: 247
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-247"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.5 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3"

- id: 248
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-248"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.vf_coef=0.03"

- id: 249
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-249"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.whiten_rewards=true"

- id: 250
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-250"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.05 trainer.args.num_ppo_epochs=3 trainer.args.whiten_rewards=true"

- id: 251
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-251"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=1.0e-6"

- id: 252
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-252"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=1.0e-7"

- id: 253
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-253"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=3.0e-7"

- id: 254
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-254"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=adaptive dataset_wrapper.reward_threshold=0.5 task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=3.0e-7 +trainer.args.missing_eos_penalty=1.0"


##########

- id: 255
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-255"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=1.0e-6"

- id: 256
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-256"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.01 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=1.0e-6"

- id: 257
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-257"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=3 trainer.args.learning_rate=4.0e-7"

- id: 258
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-258"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L1024 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.001 trainer.args.num_ppo_epochs=4 trainer.args.learning_rate=1.0e-6"

- id: 259
  name: "Qwen2-0.5B-Instruct-gsm8k-PPO-adaptive-0.5-coef.2-id-259"
  model: "Qwen/Qwen2-0.5B-Instruct"
  command: "accelerate launch --num_processes 8 --config_file ./config/deepspeed_zero2.yaml src/train.py experiment=PPO_0.5b_L512 model=qwen_instr_0.5b task=gsm8k dataset_wrapper=default task.format_reward_coefficient=0.2 trainer.args.kl_coef=0.003 trainer.args.num_ppo_epochs=6 trainer.args.learning_rate=7.0e-7"

